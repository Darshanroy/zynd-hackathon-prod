# Setup Guide

This guide walks you through setting up the Zynd Protocols Application on your local machine.

## ğŸ“‹ Prerequisites

- **Python**: 3.10 or higher
- **pip**: Latest version
- **Git**: For cloning the repository
- **API Keys**: 
  - Groq API key (for LLM)
  - Google API key (for embeddings)
  - LangSmith API key (optional, for tracing)

## ğŸš€ Installation

### Step 1: Clone the Repository

```bash
git clone <repository-url>
cd zynd-protocals-application
```

### Step 2: Create Virtual Environment

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

**Dependencies include:**
- `langchain` - LLM framework
- `langgraph` - Multi-agent orchestration
- `langchain-groq` - Groq LLM provider
- `langchain-google-genai` - Google embeddings
- `chromadb` - Vector database
- `pydantic` - Data validation
- `python-dotenv` - Environment management

### Step 4: Configure Environment Variables

Create a `.env` file in the project root:

```bash
# LLM Provider (Groq)
GROQ_API_KEY=your_groq_api_key_here

# Google (for embeddings)
GOOGLE_API_KEY=your_google_api_key_here

# LangSmith (Optional - for tracing/debugging)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=zynd-protocols
```

**Get API Keys:**
- **Groq**: [https://console.groq.com](https://console.groq.com)
- **Google AI Studio**: [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
- **LangSmith**: [https://smith.langchain.com](https://smith.langchain.com)

### Step 5: Verify Configuration

```bash
python check_env.py
```

This script checks if all required environment variables are set.

### Step 6: Prepare Vector Database

The application uses ChromaDB for RAG. Ensure you have policy documents loaded:

```bash
# If you have a chroma_db.zip file, extract it
unzip chroma_db.zip

# Otherwise, you'll need to populate the database with your documents
# (See Development Guide for details)
```

## ğŸ¯ Running the Application

### Standard Mode

```bash
python src/main.py
```

You'll see the interactive CLI:

```
=============================================
Civic Assistance Agent System (Zynd Enhanced)
---------------------------------------------
Type 'exit' or 'quit' to stop.
=============================================

User (Question): 
```

### Streamlit UI Mode (Alternative)

```bash
streamlit run src/streamlit_app.py
```

Access the web interface at `http://localhost:8501`

## ğŸ§ª Testing

Run the test suite:

```bash
# All tests
pytest

# Unit tests only
pytest tests/unit/

# Integration tests only
pytest tests/integration/

# With coverage
pytest --cov=src tests/
```

## âš™ï¸ Configuration

### LLM Provider Configuration

The default LLM is **Groq** (fast and cost-effective). To switch providers, edit [`src/agents.py`](file:///c:/Users/bhara/Desktop/Projects/zynd-protocals-application/src/agents.py):

**Use Google Gemini:**
```python
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0,
    google_api_key=os.getenv("GOOGLE_API_KEY")
)
```

**Use Ollama (Local):**
```python
from langchain_ollama import ChatOllama

llm = ChatOllama(
    model="llama3.2:3b",
    temperature=0
)
```

### Logging Configuration

Logs are stored in `logs/` directory. Configure log level in [`src/logger.py`](file:///c:/Users/bhara/Desktop/Projects/zynd-protocals-application/src/logger.py):

```python
logging.basicConfig(
    level=logging.INFO,  # Change to DEBUG for verbose logging
    ...
)
```

### Cache Configuration

LLM response caching is enabled by default via [`src/cache_helper.py`](file:///c:/Users/bhara/Desktop/Projects/zynd-protocals-application/src/cache_helper.py). To disable:

```python
# In each agent file (policy_navigator.py, etc.)
# Comment out cache checks:
# cached_result = CacheHelper.get_llm_cache(cache_key)
```

## ğŸ” Troubleshooting

### Issue: Import Errors

**Solution**: Ensure virtual environment is activated and dependencies are installed:
```bash
pip install -r requirements.txt
```

### Issue: API Rate Limits

**Solution**: 
- Check API key quotas
- Switch to a different LLM provider
- Enable caching to reduce API calls

### Issue: ChromaDB Not Found

**Solution**: Ensure `chroma_db/` directory exists:
```bash
# Check if directory exists
ls chroma_db/

# If missing, extract from backup
unzip chroma_db.zip
```

### Issue: Slow Performance

**Solutions**:
1. Use Groq instead of Ollama (20x faster)
2. Enable caching
3. Reduce retrieval chunk size in `rag.py`
4. Use smaller LLM model

### Issue: LangSmith Tracing Errors

**Solution**: LangSmith is optional. To disable, remove from `.env`:
```bash
# Comment out or remove these lines
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=...
```

## ğŸ“ Project Structure

```
zynd-protocals-application/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                      # Entry point
â”‚   â”œâ”€â”€ graph.py                     # Main orchestrator
â”‚   â”œâ”€â”€ agents.py                    # Agent configurations
â”‚   â”œâ”€â”€ state.py                     # Main state definition
â”‚   â”œâ”€â”€ schemas.py                   # Pydantic schemas
â”‚   â”œâ”€â”€ policy_navigator.py          # Policy agent
â”‚   â”œâ”€â”€ eligibility_verification.py  # Eligibility agent
â”‚   â”œâ”€â”€ benefits_matching.py         # Benefits agent
â”‚   â”œâ”€â”€ advocacy_agent.py            # Advocacy agent
â”‚   â”œâ”€â”€ rag.py                       # RAG setup
â”‚   â”œâ”€â”€ rag_agent.py                 # Agentic RAG
â”‚   â”œâ”€â”€ tools.py                     # Shared tools
â”‚   â”œâ”€â”€ prompts.py                   # System prompts
â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â”œâ”€â”€ logger.py                    # Logging setup
â”‚   â”œâ”€â”€ cache_helper.py              # LLM caching
â”‚   â””â”€â”€ langsmith_config.py          # Tracing setup
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                        # Unit tests
â”‚   â””â”€â”€ integration/                 # Integration tests
â”œâ”€â”€ docs/                            # Documentation
â”œâ”€â”€ chroma_db/                       # Vector database
â”œâ”€â”€ logs/                            # Application logs
â”œâ”€â”€ .env                             # Environment variables
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # Project README
```

## ğŸ”„ Updating

To update dependencies:

```bash
pip install --upgrade -r requirements.txt
```

To update vector database with new documents:

```bash
# See Development Guide for document ingestion process
python scripts/ingest_documents.py
```

## ğŸ³ Docker Setup (Optional)

*Coming soon: Docker and docker-compose configurations*

## âœ… Verification Checklist

After setup, verify:

- [ ] Python 3.10+ installed
- [ ] Virtual environment activated
- [ ] All dependencies installed
- [ ] `.env` file configured with API keys
- [ ] `check_env.py` passes
- [ ] ChromaDB directory exists
- [ ] Application runs without errors
- [ ] Can interact via CLI
- [ ] Tests pass

---

Next: [Agents Reference](agents.md) to understand each agent's capabilities.
